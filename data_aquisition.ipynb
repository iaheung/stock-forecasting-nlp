{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df of companies to extract data from\n",
    "filepath = \"data/companies.csv\"\n",
    "company_df = pd.read_csv(filepath)\n",
    "company_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual number of entries will be closer to around 200, since no data on market closed days\n",
    "days = 250\n",
    "start = datetime.now() - timedelta(days)\n",
    "end = datetime.now()\n",
    "\n",
    "start = datetime.strptime('2024-03-11', '%Y-%m-%d')\n",
    "end = datetime.strptime('2024-11-15', '%Y-%m-%d')\n",
    "\n",
    "for i in range(len(company_df)):\n",
    "    company = company_df.iloc[i]['Company']\n",
    "    ticker = company_df.iloc[i]['Ticker']\n",
    "    \n",
    "    filename = company.replace(' ', '_')\n",
    "    filename = filename.lower() + '.csv'\n",
    "    \n",
    "    stock_df = yf.download(ticker, start, end, progress=False)\n",
    "    \n",
    "    folder = \"data/stocks\"\n",
    "    \n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "    \n",
    "    savepath = os.path.join(folder, filename)\n",
    "    stock_df.to_csv(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_news(filename, company, api):\n",
    "    company_df = pd.read_csv(os.path.join(\"data/stocks/\", filename))\n",
    "\n",
    "    company_df['Date'] = pd.to_datetime(company_df['Date'])\n",
    "    company_df.set_index(company_df[\"Date\"], inplace=True)\n",
    "\n",
    "    company_df.drop('Date', axis=1, inplace=True) \n",
    "    company_df = company_df.tail(150)\n",
    "    \n",
    "    news_array = []\n",
    "    prev_date = company_df.index[0]\n",
    "\n",
    "    API_KEY = api\n",
    "\n",
    "    for d in company_df.index:\n",
    "        if prev_date == d:\n",
    "            date1 = d\n",
    "        else:\n",
    "            date1 = prev_date\n",
    "        date2 = d\n",
    "\n",
    "        month1, day1, year1 = date1.strftime('%m'), date1.strftime('%d'), date1.strftime('%Y')\n",
    "        month2, day2, year2 = date2.strftime('%m'), date2.strftime('%d'), date2.strftime('%Y')\n",
    "        \n",
    "        prev_date = d + timedelta(1)\n",
    "        \n",
    "        url  = f'https://api.goperigon.com/v1/all?apiKey={API_KEY}&from={year1}-{month1}-{day1}&to={year2}-{month2}-{day2}&showNumResults=true&sortBy=relevance&title=\"{company}\"'\n",
    "\n",
    "        response = requests.get(url).json()\n",
    "\n",
    "        # limit to 10 articles per day\n",
    "        if 'numResults' in response and response['numResults'] > 0:\n",
    "            num_articles = min(response['numResults'], 10)\n",
    "        else:\n",
    "            print(response)\n",
    "            print(f\"Warning: 'numResults' key missing or zero for date range {date1} to {date2}.\")\n",
    "            num_articles = 0\n",
    "\n",
    "        title_comb = \"\"\n",
    "        description_comb = \"\"\n",
    "        summary_comb = \"\"\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        neutral = 0\n",
    "\n",
    "        for i in range(num_articles):\n",
    "            title = response['articles'][i]['title']\n",
    "            desc = response['articles'][i]['description']\n",
    "            summary = response['articles'][i]['summary']\n",
    "            if 'sentiment' in response['articles'][i]:\n",
    "                sentiment = response['articles'][i]['sentiment']\n",
    "            else:\n",
    "                sentiment = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "            \n",
    "            title_comb += \" \" + title\n",
    "            description_comb += \" \" + desc\n",
    "            summary_comb += \" \" + summary\n",
    "            \n",
    "            positive += sentiment['positive']\n",
    "            negative += sentiment['negative']\n",
    "            neutral += sentiment['neutral']\n",
    "            \n",
    "        if num_articles != 0:    \n",
    "            positive = positive / num_articles\n",
    "            negative = negative / num_articles\n",
    "            neutral = neutral / num_articles\n",
    "\n",
    "            new_row = {'date': date2, 'title': title_comb, 'description': description_comb, 'summary': summary_comb, 'positive': positive, 'negative': negative, 'neutral': neutral}\n",
    "        else:\n",
    "            new_row = {'date': date2, 'title': None, 'description': None, 'summary': None, 'positive': None, 'negative': None, 'neutral': None}\n",
    "            \n",
    "        news_array.append(new_row)\n",
    "        time.sleep(5)\n",
    "        \n",
    "    df = pd.DataFrame(news_array)\n",
    "\n",
    "    news_folder = \"data/news\"\n",
    "\n",
    "    if not os.path.exists(news_folder):\n",
    "        os.mkdir(news_folder)\n",
    "\n",
    "    filename = company.lower() + \"_news.csv\"\n",
    "\n",
    "    df.to_csv(os.path.join(news_folder, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'API-KEY-HERE'\n",
    "save_news('tsmc.csv', 'TSMC', api_key)\n",
    "save_news('nvidia.csv', 'Nvidia', api_key)\n",
    "save_news('intel.csv', 'Intel', api_key)\n",
    "save_news('amd.csv', 'AMD', api_key)\n",
    "save_news('broadcom.csv', 'Broadcom',api_key)\n",
    "save_news('asml.csv', 'ASML', api_key)\n",
    "save_news('micron_technology.csv', 'Micron', api_key)\n",
    "save_news('qualcomm.csv', 'Qualcomm', api_key)\n",
    "save_news('lam_research.csv', 'Lam Research', api_key)\n",
    "save_news('samsung_electronics.csv', 'Samsung Electronics', api_key)\n",
    "save_news('texas_instruments.csv', 'Texas Instruments', api_key)\n",
    "save_news('nxp_semiconductors.csv', 'NXP', api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc371",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
