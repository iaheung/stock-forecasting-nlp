{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df of companies to extract data from\n",
    "filepath = \"data/companies.csv\"\n",
    "company_df = pd.read_csv(filepath)\n",
    "company_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twelve Data API for timeseries\n",
    "url = \"https://api.twelvedata.com/time_series\"\n",
    "api_key = \"SET_API_KEY\" # set API key\n",
    "\n",
    "for i in range(len(company_df)):\n",
    "    company = company_df.iloc[i]['Company']\n",
    "    ticker = company_df.iloc[i]['Ticker']\n",
    "    \n",
    "    filename = company.replace(' ', '_')\n",
    "    filename = filename.lower() + '.csv'\n",
    "    \n",
    "    params = {\n",
    "        \"symbol\": ticker, \n",
    "        \"interval\": \"15min\",\n",
    "        \"start_date\": \"2024-04-15\", # news data start date \n",
    "        \"end_date\": \"2024-11-15\", # news data end date\n",
    "        \"apikey\": api_key \n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data.get(\"status\") == \"ok\":\n",
    "            print(f\"{company} stock time series recieved\")\n",
    "        else:\n",
    "            print(\"Error:\", data.get(\"message\", \"Unknown error\"))\n",
    "    else:\n",
    "        print(f\"HTTP Error: {response.status_code}\")\n",
    "    \n",
    "    # convert to pandas dataframe\n",
    "    values = data[\"values\"]\n",
    "    df = pd.DataFrame(values)\n",
    "    # String to Datetime conversion\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "    # String to Float conversion\n",
    "    numeric_columns = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    df[numeric_columns] = df[numeric_columns].astype(float)\n",
    "    \n",
    "    # Extract Time data (Seconds in each day) from datetime column\n",
    "    df[\"Time\"] = df[\"datetime\"].dt.hour * 3600 + df[\"datetime\"].dt.minute * 60 + df[\"datetime\"].dt.second\n",
    "    # Seperate Date Column for joining news data\n",
    "    df[\"Date\"] = df[\"datetime\"].dt.strftime(\"%Y-%m-%d\")\n",
    "    df = df.drop(columns=[\"datetime\"])\n",
    "\n",
    "    # Capitalize colnames \n",
    "    df.columns = df.columns.str.capitalize()\n",
    "    \n",
    "    folder = \"data/twelve_data\"\n",
    "    \n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "    \n",
    "    savepath = os.path.join(folder, filename)\n",
    "    df.to_csv(savepath)\n",
    "    \n",
    "    # limited API calls per minute\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_news(filename, company, api):\n",
    "    company_df = pd.read_csv(os.path.join(\"data/stocks/\", filename))\n",
    "\n",
    "    company_df['Date'] = pd.to_datetime(company_df['Date'])\n",
    "    company_df.set_index(company_df[\"Date\"], inplace=True)\n",
    "\n",
    "    company_df.drop('Date', axis=1, inplace=True) \n",
    "    company_df = company_df.tail(150)\n",
    "    \n",
    "    news_array = []\n",
    "    prev_date = company_df.index[0]\n",
    "\n",
    "    API_KEY = api\n",
    "\n",
    "    for d in company_df.index:\n",
    "        if prev_date == d:\n",
    "            date1 = d\n",
    "        else:\n",
    "            date1 = prev_date\n",
    "        date2 = d\n",
    "\n",
    "        month1, day1, year1 = date1.strftime('%m'), date1.strftime('%d'), date1.strftime('%Y')\n",
    "        month2, day2, year2 = date2.strftime('%m'), date2.strftime('%d'), date2.strftime('%Y')\n",
    "        \n",
    "        prev_date = d + timedelta(1)\n",
    "        \n",
    "        url  = f'https://api.goperigon.com/v1/all?apiKey={API_KEY}&from={year1}-{month1}-{day1}&to={year2}-{month2}-{day2}&showNumResults=true&sortBy=relevance&title=\"{company}\"'\n",
    "\n",
    "        response = requests.get(url).json()\n",
    "\n",
    "        # limit to 10 articles per day\n",
    "        if 'numResults' in response and response['numResults'] > 0:\n",
    "            num_articles = min(response['numResults'], 10)\n",
    "        else:\n",
    "            print(response)\n",
    "            print(f\"Warning: 'numResults' key missing or zero for date range {date1} to {date2}.\")\n",
    "            num_articles = 0\n",
    "\n",
    "        title_comb = \"\"\n",
    "        description_comb = \"\"\n",
    "        summary_comb = \"\"\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        neutral = 0\n",
    "\n",
    "        for i in range(num_articles):\n",
    "            title = response['articles'][i]['title']\n",
    "            desc = response['articles'][i]['description']\n",
    "            summary = response['articles'][i]['summary']\n",
    "            if 'sentiment' in response['articles'][i]:\n",
    "                sentiment = response['articles'][i]['sentiment']\n",
    "            else:\n",
    "                sentiment = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "            \n",
    "            title_comb += \" \" + title\n",
    "            description_comb += \" \" + desc\n",
    "            summary_comb += \" \" + summary\n",
    "            \n",
    "            positive += sentiment['positive']\n",
    "            negative += sentiment['negative']\n",
    "            neutral += sentiment['neutral']\n",
    "            \n",
    "        if num_articles != 0:    \n",
    "            positive = positive / num_articles\n",
    "            negative = negative / num_articles\n",
    "            neutral = neutral / num_articles\n",
    "\n",
    "            new_row = {'date': date2, 'title': title_comb, 'description': description_comb, 'summary': summary_comb, 'positive': positive, 'negative': negative, 'neutral': neutral}\n",
    "        else:\n",
    "            new_row = {'date': date2, 'title': None, 'description': None, 'summary': None, 'positive': None, 'negative': None, 'neutral': None}\n",
    "            \n",
    "        news_array.append(new_row)\n",
    "        time.sleep(5)\n",
    "        \n",
    "    df = pd.DataFrame(news_array)\n",
    "\n",
    "    news_folder = \"data/news\"\n",
    "\n",
    "    if not os.path.exists(news_folder):\n",
    "        os.mkdir(news_folder)\n",
    "\n",
    "    filename = company.lower() + \"_news.csv\"\n",
    "\n",
    "    df.to_csv(os.path.join(news_folder, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'API-KEY-HERE'\n",
    "\n",
    "# I could have done this in a loop, but I could only do 150 API calls for one API key\n",
    "save_news('tsmc.csv', 'TSMC', api_key)\n",
    "save_news('nvidia.csv', 'Nvidia', api_key)\n",
    "save_news('intel.csv', 'Intel', api_key)\n",
    "save_news('amd.csv', 'AMD', api_key)\n",
    "save_news('broadcom.csv', 'Broadcom',api_key)\n",
    "save_news('asml.csv', 'ASML', api_key)\n",
    "save_news('micron_technology.csv', 'Micron', api_key)\n",
    "save_news('qualcomm.csv', 'Qualcomm', api_key)\n",
    "save_news('lam_research.csv', 'Lam Research', api_key)\n",
    "save_news('samsung_electronics.csv', 'Samsung Electronics', api_key)\n",
    "save_news('texas_instruments.csv', 'Texas Instruments', api_key)\n",
    "save_news('nxp_semiconductors.csv', 'NXP', api_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
