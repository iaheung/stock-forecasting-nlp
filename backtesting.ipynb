{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions for model training\n",
    "\"\"\"\n",
    "\n",
    "def df_to_Xy(df, window_size=10):\n",
    "  df_as_np = df.to_numpy()\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size):\n",
    "    row = [r for r in df_as_np[i:i+window_size]]\n",
    "    X.append(row)\n",
    "    label = df_as_np[i+window_size][3]\n",
    "    y.append(label)\n",
    "  return np.array(X), np.array(y)\n",
    "\n",
    "def df_to_Xy_future(df, window_size=10, future_step=2):\n",
    "    \"\"\"\n",
    "    Converts a DataFrame into sequences of input data (X) and labels (y).\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - window_size: Number of past data points to include in each input sequence.\n",
    "    - future_step: Number of steps ahead to predict.\n",
    "\n",
    "    Returns:\n",
    "    - X: Input features as numpy array.\n",
    "    - y: Target labels as numpy array.\n",
    "    \"\"\"\n",
    "    df_as_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np) - window_size - future_step):\n",
    "        # Extract the sequence of features\n",
    "        row = df_as_np[i:i + window_size]\n",
    "        X.append(row)\n",
    "        # Extract the target label future_step ahead\n",
    "        label = df_as_np[i + window_size + future_step - 1][3]  # Index 3 is 'Close'\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# standardize the data with training set mean and standard deviation                 \n",
    "def preprocess(X, mean, std, i):\n",
    "  X[:, :, i] = (X[:, :, i] - mean) / std\n",
    "  return X\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "  def __init__(self):\n",
    "      super(CNNModel, self).__init__()\n",
    "      # Conv1D layer\n",
    "      self.conv1d = nn.Conv1d(in_channels=7, out_channels=64, kernel_size=2)\n",
    "      # Flatten layer is implicit in PyTorch\n",
    "      self.fc1 = nn.Linear(64 * 9, 8)  # Adjusted input size to 64 * 4 = 256\n",
    "      self.relu = nn.ReLU()\n",
    "      self.fc2 = nn.Linear(8, 1)  # Final output layer\n",
    "\n",
    "  def forward(self, x):\n",
    "      x = self.conv1d(x)  # Apply Conv1D\n",
    "      #print(f\"After Conv1D: {x.shape}\")  # Debugging: Print shape after Conv1D\n",
    "      x = x.view(x.size(0), -1)  # Flatten (equivalent to Flatten layer in Keras)\n",
    "      #print(f\"After Flatten: {x.shape}\")  # Debugging: Print shape after flatten\n",
    "      x = self.relu(self.fc1(x))  # Fully connected + ReLU\n",
    "      x = self.fc2(x)  # Final linear layer\n",
    "      return x\n",
    "\n",
    "# Function to plot predictions\n",
    "def plot_predictions(model, X, y, title, plot_dir, filename, mean, std):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Transpose X to match Conv1D input format (Batch Size, Channels, Sequence Length)\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).transpose(1, 2)\n",
    "        predictions = model(X_tensor).flatten().numpy()  # Get predictions\n",
    "\n",
    "    # Create a DataFrame to compare predictions with actuals\n",
    "    df = pd.DataFrame(data={\"Predictions\": predictions, \"Actuals\": y})\n",
    "\n",
    "    # Plot predictions vs. actuals\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df[\"Predictions\"], label=\"Predictions\")\n",
    "    plt.plot(df[\"Actuals\"], label=\"Actuals\")\n",
    "    plt.ylabel(\"Stock Price ($)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot in the date-based directory\n",
    "    plt.savefig(os.path.join(plot_dir, filename))\n",
    "    plt.close()\n",
    "\n",
    "    return df, mean_absolute_error(y, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot predictions\n",
    "def plot_whole(model, X, y, title, show_plot):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    with torch.no_grad():\n",
    "      # Transpose X to match Conv1D input format (Batch Size, Channels, Sequence Length)\n",
    "      X_tensor = torch.tensor(X, dtype=torch.float32).transpose(1, 2)\n",
    "      predictions = model(X_tensor).flatten().numpy()  # Get predictions\n",
    "\n",
    "    # Create a DataFrame to compare predictions with actuals\n",
    "    df = pd.DataFrame(data={\"Predictions\": predictions, \"Actuals\": y})\n",
    "    \n",
    "    # Plot predictions vs. actuals\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df[\"Predictions\"], label=\"Predictions\")\n",
    "    plt.plot(df[\"Actuals\"], label=\"Actuals\")\n",
    "    plt.ylabel(\"Stock Price ($)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    \n",
    "    if show_plot:\n",
    "      plt.show()\n",
    "    plt.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strategy(df, initial_capital=10000, transaction_cost=0.0, \n",
    "                      price_change_threshold=0.002, rolling_window=40, \n",
    "                      cooldown_period=4, trend_window=4, initial_stock_allocation=0.5, \n",
    "                      trade_proportion=0.50):\n",
    "    \"\"\"\n",
    "    Backtests a refined trading strategy using predictions and actual prices.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with 'Predictions' and 'Actuals' columns.\n",
    "    - initial_capital: Starting capital for the backtest.\n",
    "    - transaction_cost: Proportional transaction cost (e.g., 0.001 for 0.1% cost).\n",
    "    - price_change_threshold: Minimum price change percentage to trigger a trade (e.g., 0.05 for 5%).\n",
    "    - rolling_window: Window size for rolling averages.\n",
    "    - cooldown_period: Minimum steps between trades.\n",
    "    - trend_window: Minimum consecutive steps for a trend.\n",
    "    - initial_stock_allocation: Fraction of the initial portfolio to allocate to stock holdings (default: 50%).\n",
    "    - trade_proportion: Fraction of the position or capital to trade (default: 25%).\n",
    "\n",
    "    Returns:\n",
    "    - portfolio: List of portfolio values over time.\n",
    "    - final_value: Final portfolio value.\n",
    "    - trade_counts: Tuple of total buys and sells (Buys, Sells).\n",
    "    - final_capital: Final free cash flow.\n",
    "    - final_stock_value: Value of stocks held at the end.\n",
    "    \"\"\"\n",
    "    # Calculate initial stock holdings\n",
    "    starting_stock_value = initial_capital * initial_stock_allocation\n",
    "    initial_stock_price = df['Actuals'].iloc[0]\n",
    "    position = starting_stock_value // initial_stock_price  # Number of shares\n",
    "    capital = initial_capital - position * initial_stock_price  # Remaining free cash after purchase\n",
    "\n",
    "    portfolio = [capital + position * initial_stock_price]  # Start with total portfolio value\n",
    "    last_trade = -cooldown_period  # Initialise cooldown tracker\n",
    "    max_price_since_buy = 0  # Track highest price since last buy\n",
    "\n",
    "    # Trade counters\n",
    "    buy_count = 0\n",
    "    sell_count = 0\n",
    "    \n",
    "    # Calculate rolling averages for predictions and actuals\n",
    "    df['Smoothed_Predictions'] = df['Predictions'].rolling(rolling_window).mean()\n",
    "    df['Smoothed_Actuals'] = df['Actuals'].rolling(rolling_window).mean()\n",
    "    \n",
    "    # Calculate moving averages for technical indicator\n",
    "    df['Short_MA'] = df['Actuals'].rolling(window=5).mean()\n",
    "    df['Long_MA'] = df['Actuals'].rolling(window=20).mean()\n",
    "\n",
    "    for i in range(max(rolling_window, 20), len(df)):\n",
    "        # Update live portfolio value\n",
    "        portfolio_value = capital + position * df['Actuals'].iloc[i]\n",
    "\n",
    "        stop_loss_triggered = False\n",
    "        \n",
    "        # Skip if cooldown period not met\n",
    "        if i - last_trade < cooldown_period:\n",
    "            portfolio.append(portfolio_value)\n",
    "            continue\n",
    "\n",
    "        # Trend indicators\n",
    "        is_uptrend = all(df['Smoothed_Predictions'].iloc[i - j] > df['Smoothed_Predictions'].iloc[i - j - 1] for j in range(1, trend_window + 1))\n",
    "        is_downtrend = all(df['Smoothed_Predictions'].iloc[i - j] < df['Smoothed_Predictions'].iloc[i - j - 1] for j in range(1, trend_window + 1))\n",
    "        steep_drop = df['Smoothed_Predictions'].iloc[i] < df['Smoothed_Predictions'].iloc[i - trend_window] * (1 - price_change_threshold)\n",
    "        recent_momentum = (df['Actuals'].iloc[i] - df['Actuals'].iloc[i - trend_window]) / df['Actuals'].iloc[i - trend_window]\n",
    "        steep_decline = recent_momentum < -price_change_threshold\n",
    "        slow_growth = all(df['Smoothed_Predictions'].iloc[i - j] < df['Smoothed_Predictions'].iloc[i - j + 1] for j in range(trend_window, trend_window + 5))\n",
    "\n",
    "        # Dynamic trade proportion\n",
    "        trend_strength = abs(df['Smoothed_Predictions'].iloc[i] - df['Smoothed_Predictions'].iloc[i - trend_window]) / df['Smoothed_Predictions'].iloc[i - trend_window]\n",
    "        trade_proportion = min(0.5, max(0.1, trend_strength))\n",
    "\n",
    "        # Moving averages\n",
    "        short_ma = df['Short_MA'].iloc[i]\n",
    "        long_ma = df['Long_MA'].iloc[i]\n",
    "        ma_crossover_up = short_ma > long_ma\n",
    "        ma_crossover_down = short_ma < long_ma\n",
    "\n",
    "        # Stop-loss tracking\n",
    "        if position > 0:\n",
    "            max_price_since_buy = max(max_price_since_buy, df['Actuals'].iloc[i])\n",
    "            stop_loss_triggered = df['Actuals'].iloc[i] < max_price_since_buy * (1 - 0.1)  # 10% drop\n",
    "\n",
    "        # Trading logic\n",
    "        if (is_uptrend or slow_growth) and ma_crossover_up:  # Buy\n",
    "            max_shares_to_buy = capital // df['Actuals'].iloc[i]\n",
    "            shares_to_buy = int(max_shares_to_buy * trade_proportion)\n",
    "            if shares_to_buy > 0:\n",
    "                capital -= shares_to_buy * df['Actuals'].iloc[i] * (1 + transaction_cost)\n",
    "                position += shares_to_buy\n",
    "                max_price_since_buy = df['Actuals'].iloc[i]  # Update after buying\n",
    "                last_trade = i\n",
    "                buy_count += 1\n",
    "        elif (is_downtrend or steep_drop or steep_decline or ma_crossover_down or stop_loss_triggered):  # Sell\n",
    "            shares_to_sell = int(position * trade_proportion)\n",
    "            if shares_to_sell > 0:\n",
    "                capital += shares_to_sell * df['Actuals'].iloc[i] * (1 - transaction_cost)\n",
    "                position -= shares_to_sell\n",
    "                last_trade = i\n",
    "                sell_count += 1\n",
    "\n",
    "        # Append updated portfolio value\n",
    "        portfolio_value = capital + position * df['Actuals'].iloc[i]\n",
    "        portfolio.append(portfolio_value)\n",
    "\n",
    "    # Final portfolio components\n",
    "    final_stock_value = position * df['Actuals'].iloc[-1]\n",
    "    final_value = capital + final_stock_value\n",
    "\n",
    "    # Return buy and sell counts as a tuple\n",
    "    trade_counts = (buy_count, sell_count)\n",
    "    \n",
    "    return portfolio, final_value, trade_counts, capital, final_stock_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_backtest(company, checkpoint_path, show_plot=False, future=False):# change company dataset\n",
    "    company = company.lower().replace(' ', '_')\n",
    "    \n",
    "    df = pd.read_csv(f\"data/processed/{company}_processed.csv\")\n",
    "    df = df[['Open', 'High', 'Low', 'Close', 'Volume', 'Time', 'Finbert_score']]\n",
    "\n",
    "    df.fillna(method='ffill', inplace=True)  # Replace NaNs with the previous row's values\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    if future:\n",
    "        X, y = df_to_Xy_future(df)\n",
    "    else:\n",
    "        X, y = df_to_Xy(df)\n",
    "    \n",
    "    \n",
    "    X_train = X[:2000]\n",
    "\n",
    "    for i in range(2, len(X_train[0,0])):\n",
    "        mean = np.mean(X_train[:, :, i]) # mean of training temp\n",
    "        std = np.std(X_train[:, :, i]) # std of training temp\n",
    "        preprocess(X, mean, std, i)\n",
    "\n",
    "        # Instantiate the model\n",
    "    backtest_model = CNNModel()\n",
    "\n",
    "    # change checkpoint path\n",
    "    #nvidia_path = 'checkpoints/20241125/intel/checkpoint_epoch_474.pth'\n",
    "    backtest_checkpoint = torch.load(checkpoint_path)\n",
    "    backtest_model.load_state_dict(backtest_checkpoint['model_state_dict'])\n",
    "\n",
    "    # change plot title\n",
    "    df = plot_whole(backtest_model, X, y, company, show_plot)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def backtest(df, initial_capital=100000, show_plot=True):\n",
    "    # Example usage:\n",
    "    portfolio, final_value, num_trades, free_cash_flow, held_value = backtest_strategy(df, initial_capital=initial_capital)\n",
    "    print(f\"Final Portfolio Value: {final_value}\")\n",
    "    print(f'Number of Trades: {num_trades}')\n",
    "    print(\"Realized Gain: \", final_value - initial_capital)\n",
    "    print(f\"Final Free Cash Flow (Capital): {free_cash_flow}\")\n",
    "    print(f\"Final Value Held in Stocks: {held_value}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(portfolio, label='Portfolio Value')\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Portfolio Value')\n",
    "    plt.title('Backtest Portfolio Performance')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    return portfolio, final_value, num_trades, free_cash_flow, held_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_and_checkpoint(file_path):\n",
    "    checkpoint_paths = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.strip():  # Skip empty lines\n",
    "                company = line.split(\", Best Epoch\")[0].replace(\"Company: \", \"\").strip()\n",
    "\n",
    "                checkpoint_path = line.split(\"Checkpoint: \")[1].strip().replace(\"\\\\\", \"/\")\n",
    "\n",
    "                checkpoint_paths.append((company, checkpoint_path))\n",
    "    return checkpoint_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Sharpe Ratio\n",
    "def compute_sharpe_ratio(portfolio, risk_free_rate, trading_days=252):\n",
    "    # Calculate daily returns from portfolio values\n",
    "    returns = np.diff(portfolio) / portfolio[:-1]\n",
    "\n",
    "    # Convert risk-free rate to daily (assuming 252 trading days per year)\n",
    "    daily_risk_free_rate = (1 + risk_free_rate) ** (1 / trading_days) - 1\n",
    "\n",
    "    # Calculate excess returns\n",
    "    excess_returns = returns - daily_risk_free_rate\n",
    "\n",
    "    # Compute Sharpe Ratio\n",
    "    sharpe_ratio = np.mean(excess_returns) / np.std(excess_returns)\n",
    "\n",
    "    # Annualize Sharpe Ratio (if needed)\n",
    "    annualized_sharpe = sharpe_ratio * np.sqrt(trading_days)\n",
    "\n",
    "    return sharpe_ratio, annualized_sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"company\", \"portfolio\", \"final_value\", \"num_trades\", \"free_cash_flow\", \"held_value\"]\n",
    "\n",
    "backtest_results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "file_path = \"best_epochs/20241126/best_epochs_20241126114831.txt\"\n",
    "checkpoint_paths = extract_company_and_checkpoint(file_path)\n",
    "\n",
    "risk_free_rate = 0.02\n",
    "for tup in checkpoint_paths:\n",
    "    company = tup[0]\n",
    "    checkpoint_path = tup[1]\n",
    "    df = initialize_backtest(company, checkpoint_path, show_plot=False)\n",
    "    \n",
    "    portfolio, final_value, num_trades, free_cash_flow, held_value = backtest(df, initial_capital=100000)\n",
    "    backtest_results_df = pd.concat([backtest_results_df, pd.DataFrame([{\n",
    "        \"company\": company,\n",
    "        \"portfolio\": portfolio,\n",
    "        \"final_value\": final_value,\n",
    "        \"num_trades\": num_trades,\n",
    "        \"free_cash_flow\": free_cash_flow,\n",
    "        \"held_value\": held_value\n",
    "    }])], ignore_index=True)\n",
    "    \n",
    "    sharpe, annualized_sharpe = compute_sharpe_ratio(portfolio, risk_free_rate, trading_days=209)\n",
    "\n",
    "    print(f\"Sharpe Ratio: {sharpe:.2f}, Annualized Sharpe Ratio: {annualized_sharpe:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Grid search function\n",
    "def grid_search_backtest(df, initial_capital=10000, risk_free_rate=0.02, trading_days=252):\n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'transaction_cost': [0.0],\n",
    "        'price_change_threshold': [0.001, 0.002, 0.005],\n",
    "        'rolling_window': [20, 40, 60],\n",
    "        'cooldown_period': [2, 4, 8, 16],\n",
    "        'trend_window': [2, 4, 8, 16],\n",
    "        'initial_stock_allocation': [0.3, 0.5, 0.7],\n",
    "        'trade_proportion': [0.25, 0.5, 0.75]\n",
    "    }\n",
    "\n",
    "    # Create all combinations of parameters\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "    # Column names for the results DataFrame\n",
    "    columns = list(param_grid.keys()) + [\"sharpe_ratio\", \"annualized_sharpe\"]\n",
    "\n",
    "    # Initialize results DataFrame\n",
    "    results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Perform grid search\n",
    "    for params in tqdm(param_combinations, desc=\"Grid Search\"):\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "\n",
    "        # Run backtest with the current parameter set\n",
    "        portfolio, final_value, _, _, _ = backtest_strategy(\n",
    "            df,\n",
    "            initial_capital=initial_capital,\n",
    "            transaction_cost=param_dict['transaction_cost'],\n",
    "            price_change_threshold=param_dict['price_change_threshold'],\n",
    "            rolling_window=param_dict['rolling_window'],\n",
    "            cooldown_period=param_dict['cooldown_period'],\n",
    "            trend_window=param_dict['trend_window'],\n",
    "            initial_stock_allocation=param_dict['initial_stock_allocation'],\n",
    "            trade_proportion=param_dict['trade_proportion']\n",
    "        )\n",
    "\n",
    "        # Compute Sharpe ratio\n",
    "        sharpe, annualized_sharpe = compute_sharpe_ratio(portfolio, risk_free_rate, trading_days)\n",
    "\n",
    "        # Store results\n",
    "        result = {**param_dict, \"sharpe_ratio\": sharpe, \"annualized_sharpe\": annualized_sharpe}\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([result])], ignore_index=True)\n",
    "\n",
    "    # Return sorted results by Sharpe ratio\n",
    "    return results_df.sort_values(by=\"annualized_sharpe\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"best_epochs/20241126/best_epochs_20241126195347.txt\"\n",
    "checkpoint_paths = extract_company_and_checkpoint(file_path)\n",
    "\n",
    "for tup in checkpoint_paths:\n",
    "    company = tup[0]\n",
    "    checkpoint_path = tup[1]\n",
    "    \n",
    "    print(f\"Computing Best Sharpe for {company}\")\n",
    "    \n",
    "    df = initialize_backtest(company, checkpoint_path, show_plot=False)\n",
    "\n",
    "    # Perform grid search\n",
    "    results = grid_search_backtest(df, initial_capital=100000, risk_free_rate=0.02, trading_days=209)\n",
    "\n",
    "    backtest_path = 'backtest_results'\n",
    "    if not os.path.exists(backtest_path):\n",
    "        os.makedirs(backtest_path)\n",
    "        \n",
    "    results.to_csv(os.path.join(backtest_path, f\"{company.lower().replace(' ', '_')}_grid_search_results.csv\"), index=False)\n",
    "\n",
    "    print(f\"{company} - Top 5 configurations:\")\n",
    "    print(results.head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
